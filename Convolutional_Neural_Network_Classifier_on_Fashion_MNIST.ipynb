{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaGArfMj2CKh"
      },
      "source": [
        "Import PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSlphUIuzeGU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N40IknUP03oy",
        "outputId": "326fd74a-14a9-48e1-8601-0c86ee1f279c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ctudn4461ecy",
        "outputId": "3395df27-8d92-4024-ea50-296edf642bc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9HOv4aX1sXi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da8746e9-6a20-4d12-c131-1c1e272c2ba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 12.4MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 202kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.76MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 8.33MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.ToTensor()\n",
        "batch_size = 8    #This means the GPU is going to handle 8 different examples at a time\n",
        "\n",
        "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "classes = ('T-shirt/top', 'Trouser/pants', 'Pullover shirt', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RF3fJI8B3gM4",
        "outputId": "f21e1658-a157-41b5-c12d-a4c674a42a46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), 9)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_iter = iter(trainset)\n",
        "\n",
        "image, label = next(train_iter)\n",
        "\n",
        "image.shape, label\n",
        "\n",
        "#The label is 9, it should be a class of an Ankle boot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66sd6ojl4Rkz",
        "outputId": "04540f88-ec55-4ea4-a72d-abd3fdbfc3d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "torch.min(image).item(), torch.max(image).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "d4TWuL444m5g",
        "outputId": "01e11c89-d77b-49e9-83db-75d747fb5a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ankle boot\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x792dba2099d0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "np_img = image.numpy()\n",
        "print(classes[label])\n",
        "plt.imshow(np_img.reshape((28, 28, 1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7Uz1JtF5Trd",
        "outputId": "d13e15fd-a8ad-474c-9c2b-5f1d422c4d34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(trainset), len(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E2sp5DG5iV7",
        "outputId": "53450d79-3ceb-40a1-e9ad-2428b3a0d372"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "trainset, valset = torch.utils.data.random_split(trainset, [50000, 10000])\n",
        "len(trainset), len(valset), len(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbGmrGSn9AV7",
        "outputId": "e61cd412-5f47-43ed-eab6-5b30f20920e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of batches in the training set: 6250.0\n",
            "Number of batches in the validation set: 1250.0\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of batches in the training set: {len(trainset) / batch_size}')\n",
        "print(f'Number of batches in the validation set: {len(valset) / batch_size}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "TYEKPlYX9VmC",
        "outputId": "930fd8de-ad11-4068-8904-f63c6084f33b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.Subset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torch.utils.data.dataset.Subset</b><br/>def __init__(dataset: Dataset[_T_co], indices: Sequence[int]) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataset.py</a>Subset of a dataset at specified indices.\n",
              "\n",
              "Args:\n",
              "    dataset (Dataset): The whole Dataset\n",
              "    indices (sequence): Indices in the whole set selected for subset</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 393);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "type(trainset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4_ty0uo9dW1"
      },
      "outputs": [],
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRhE5UMP9_5i"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=256, kernel_size=3)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=2)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=4096, out_features=1024)\n",
        "        self.drop1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.fc2 = nn.Linear(in_features=1024, out_features=1024)\n",
        "        self.drop2 = nn.Dropout(0.3)\n",
        "\n",
        "        self.out = nn.Linear(in_features=1024, out_features=10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.drop1(x)\n",
        "\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.drop2(x)\n",
        "\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12XFggBc_GyL",
        "outputId": "371f5e43-acc7-463e-96c8-fc052750be79"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNetwork(\n",
              "  (conv1): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(512, 1024, kernel_size=(2, 2), stride=(1, 1))\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "  (drop1): Dropout(p=0.3, inplace=False)\n",
              "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "  (drop2): Dropout(p=0.3, inplace=False)\n",
              "  (out): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "net = NeuralNetwork()\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF5ARAtj_Xfu",
        "outputId": "d5733c26-29f8-4334-812f-c17f6a93fcd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input shape: torch.Size([8, 1, 28, 28])\n",
            "after network shape: torch.Size([8, 10])\n"
          ]
        }
      ],
      "source": [
        "for i, data in enumerate(trainloader):\n",
        "  inputs, labels = data[0].to(device), data[1].to(device)\n",
        "  print(f'input shape: {inputs.shape}')\n",
        "  print(f'after network shape: {net(inputs).shape}')\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "866ks1oTAKjH",
        "outputId": "78354892-7334-4137-e870-c1cda6336e4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 8,536,074\n"
          ]
        }
      ],
      "source": [
        "num_params = 0\n",
        "for x in net.parameters():\n",
        "  num_params += len(torch.flatten(x))\n",
        "\n",
        "print(f'Number of parameters: {num_params:,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKgkj0wMFa3u"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmUxjqvIGSOK"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch():\n",
        "  net.train(True)\n",
        "\n",
        "  running_loss = 0.0\n",
        "  running_accuracy = 0.0\n",
        "\n",
        "  for batch_index, data in enumerate(trainloader):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = net(inputs) #shape: [batch_size, 10]\n",
        "    correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
        "    running_accuracy += correct / batch_size\n",
        "\n",
        "    loss = criterion(outputs, labels)\n",
        "    running_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch_index % 500 == 499:  #Will print every 500 batches\n",
        "      avg_loss_across_batches = running_loss / 500\n",
        "      avg_acc_across_batches = (running_accuracy / 500) * 100\n",
        "      print(f'Batch {batch_index + 1}    Loss: {avg_loss_across_batches:0.3f}    Accuracy: {avg_acc_across_batches:0.1f}%')\n",
        "\n",
        "      running_loss = 0.0\n",
        "      running_accuracy = 0.0\n",
        "\n",
        "  print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzRd1T3Mg7b4"
      },
      "outputs": [],
      "source": [
        "def validate_one_epoch():\n",
        "  net.train(False)\n",
        "\n",
        "  running_loss = 0.0\n",
        "  running_accuracy = 0.0\n",
        "\n",
        "  for i in enumerate(valloader):\n",
        "    inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "    with torch.no_grad():  #Since we are only validating the model, we don't need gradients to train it\n",
        "      outputs = net(inputs)\n",
        "      correct = torch.sum(labels == torch.argmax(outputs, dim=1)).item()\n",
        "      running_accuracy += correct / batch_size\n",
        "\n",
        "      loss = criterion(outputs, labels) #This output is the average batch loss\n",
        "      running_loss += loss.item()\n",
        "\n",
        "  avg_loss_across_batches = running_loss / len(valloader)\n",
        "  avg_acc_across_batches = (running_accuracy / len(valloader)) * 100\n",
        "\n",
        "  print(f'Validation Loss: {avg_loss_across_batches:0.3f}     Validation Accuracy: {avg_acc_across_batches:0.1f}%')\n",
        "  print('********************************************************')\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuirC5vNFn3X",
        "outputId": "c4804aaa-101c-4acd-9bf7-5d9abd57e19d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1\n",
            "\n",
            "Batch 500    Loss: 1.180    Accuracy: 54.9%\n",
            "Batch 1000    Loss: 0.739    Accuracy: 72.4%\n",
            "Batch 1500    Loss: 0.640    Accuracy: 75.8%\n",
            "Batch 2000    Loss: 0.587    Accuracy: 77.0%\n",
            "Batch 2500    Loss: 0.577    Accuracy: 78.3%\n",
            "Batch 3000    Loss: 0.513    Accuracy: 80.8%\n",
            "Batch 3500    Loss: 0.492    Accuracy: 81.6%\n",
            "Batch 4000    Loss: 0.475    Accuracy: 82.6%\n",
            "Batch 4500    Loss: 0.433    Accuracy: 84.0%\n",
            "Batch 5000    Loss: 0.426    Accuracy: 84.6%\n",
            "Batch 5500    Loss: 0.425    Accuracy: 84.0%\n",
            "Batch 6000    Loss: 0.431    Accuracy: 83.8%\n",
            "\n",
            "Validation Loss: 0.550     Validation Accuracy: 75.0%\n",
            "********************************************************\n",
            "\n",
            "Epoch: 2\n",
            "\n",
            "Batch 500    Loss: 0.388    Accuracy: 85.8%\n",
            "Batch 1000    Loss: 0.339    Accuracy: 87.4%\n",
            "Batch 1500    Loss: 0.368    Accuracy: 86.2%\n",
            "Batch 2000    Loss: 0.352    Accuracy: 86.6%\n",
            "Batch 2500    Loss: 0.349    Accuracy: 87.4%\n",
            "Batch 3000    Loss: 0.334    Accuracy: 88.0%\n",
            "Batch 3500    Loss: 0.369    Accuracy: 87.1%\n",
            "Batch 4000    Loss: 0.350    Accuracy: 86.8%\n",
            "Batch 4500    Loss: 0.330    Accuracy: 88.1%\n",
            "Batch 5000    Loss: 0.320    Accuracy: 88.8%\n",
            "Batch 5500    Loss: 0.330    Accuracy: 87.6%\n",
            "Batch 6000    Loss: 0.325    Accuracy: 88.3%\n",
            "\n",
            "Validation Loss: 0.410     Validation Accuracy: 75.0%\n",
            "********************************************************\n",
            "\n",
            "Epoch: 3\n",
            "\n",
            "Batch 500    Loss: 0.276    Accuracy: 89.6%\n",
            "Batch 1000    Loss: 0.302    Accuracy: 88.6%\n",
            "Batch 1500    Loss: 0.289    Accuracy: 89.6%\n",
            "Batch 2000    Loss: 0.266    Accuracy: 89.7%\n",
            "Batch 2500    Loss: 0.269    Accuracy: 90.1%\n",
            "Batch 3000    Loss: 0.289    Accuracy: 88.8%\n",
            "Batch 3500    Loss: 0.284    Accuracy: 89.4%\n",
            "Batch 4000    Loss: 0.280    Accuracy: 89.8%\n",
            "Batch 4500    Loss: 0.311    Accuracy: 88.9%\n",
            "Batch 5000    Loss: 0.285    Accuracy: 89.7%\n",
            "Batch 5500    Loss: 0.289    Accuracy: 89.1%\n",
            "Batch 6000    Loss: 0.267    Accuracy: 90.1%\n",
            "\n",
            "Validation Loss: 0.261     Validation Accuracy: 100.0%\n",
            "********************************************************\n",
            "\n",
            "Epoch: 4\n",
            "\n",
            "Batch 500    Loss: 0.250    Accuracy: 90.7%\n",
            "Batch 1000    Loss: 0.244    Accuracy: 90.8%\n",
            "Batch 1500    Loss: 0.229    Accuracy: 92.0%\n",
            "Batch 2000    Loss: 0.263    Accuracy: 90.3%\n",
            "Batch 2500    Loss: 0.259    Accuracy: 90.5%\n",
            "Batch 3000    Loss: 0.251    Accuracy: 90.6%\n",
            "Batch 3500    Loss: 0.252    Accuracy: 90.8%\n",
            "Batch 4000    Loss: 0.252    Accuracy: 90.6%\n",
            "Batch 4500    Loss: 0.249    Accuracy: 90.8%\n",
            "Batch 5000    Loss: 0.244    Accuracy: 91.1%\n",
            "Batch 5500    Loss: 0.242    Accuracy: 91.1%\n",
            "Batch 6000    Loss: 0.258    Accuracy: 90.3%\n",
            "\n",
            "Validation Loss: 0.296     Validation Accuracy: 87.5%\n",
            "********************************************************\n",
            "\n",
            "Epoch: 5\n",
            "\n",
            "Batch 500    Loss: 0.203    Accuracy: 92.7%\n",
            "Batch 1000    Loss: 0.237    Accuracy: 91.0%\n",
            "Batch 1500    Loss: 0.219    Accuracy: 91.5%\n",
            "Batch 2000    Loss: 0.211    Accuracy: 92.0%\n",
            "Batch 2500    Loss: 0.227    Accuracy: 91.4%\n",
            "Batch 3000    Loss: 0.231    Accuracy: 91.6%\n",
            "Batch 3500    Loss: 0.219    Accuracy: 91.3%\n",
            "Batch 4000    Loss: 0.218    Accuracy: 92.0%\n",
            "Batch 4500    Loss: 0.215    Accuracy: 91.9%\n",
            "Batch 5000    Loss: 0.217    Accuracy: 91.8%\n",
            "Batch 5500    Loss: 0.206    Accuracy: 92.6%\n",
            "Batch 6000    Loss: 0.200    Accuracy: 92.4%\n",
            "\n",
            "Validation Loss: 0.236     Validation Accuracy: 87.5%\n",
            "********************************************************\n",
            "\n",
            "Epoch: 6\n",
            "\n",
            "Batch 500    Loss: 0.177    Accuracy: 93.4%\n",
            "Batch 1000    Loss: 0.193    Accuracy: 93.0%\n",
            "Batch 1500    Loss: 0.183    Accuracy: 93.2%\n",
            "Batch 2000    Loss: 0.192    Accuracy: 92.9%\n",
            "Batch 2500    Loss: 0.193    Accuracy: 92.8%\n",
            "Batch 3000    Loss: 0.200    Accuracy: 92.9%\n",
            "Batch 3500    Loss: 0.199    Accuracy: 92.7%\n",
            "Batch 4000    Loss: 0.184    Accuracy: 93.5%\n",
            "Batch 4500    Loss: 0.187    Accuracy: 92.6%\n",
            "Batch 5000    Loss: 0.200    Accuracy: 92.8%\n",
            "Batch 5500    Loss: 0.192    Accuracy: 93.0%\n",
            "Batch 6000    Loss: 0.215    Accuracy: 92.1%\n",
            "\n",
            "Validation Loss: 0.311     Validation Accuracy: 87.5%\n",
            "********************************************************\n",
            "\n",
            "Epoch: 7\n",
            "\n",
            "Batch 500    Loss: 0.150    Accuracy: 94.5%\n",
            "Batch 1000    Loss: 0.177    Accuracy: 93.6%\n",
            "Batch 1500    Loss: 0.163    Accuracy: 93.7%\n",
            "Batch 2000    Loss: 0.157    Accuracy: 94.4%\n",
            "Batch 2500    Loss: 0.165    Accuracy: 93.8%\n",
            "Batch 3000    Loss: 0.166    Accuracy: 93.7%\n",
            "Batch 3500    Loss: 0.168    Accuracy: 93.5%\n",
            "Batch 4000    Loss: 0.191    Accuracy: 92.7%\n",
            "Batch 4500    Loss: 0.154    Accuracy: 94.3%\n",
            "Batch 5000    Loss: 0.173    Accuracy: 93.4%\n",
            "Batch 5500    Loss: 0.192    Accuracy: 93.0%\n",
            "Batch 6000    Loss: 0.185    Accuracy: 93.5%\n",
            "\n",
            "Validation Loss: 0.298     Validation Accuracy: 75.0%\n",
            "********************************************************\n",
            "\n",
            "Epoch: 8\n",
            "\n",
            "Batch 500    Loss: 0.144    Accuracy: 94.9%\n",
            "Batch 1000    Loss: 0.140    Accuracy: 94.6%\n",
            "Batch 1500    Loss: 0.152    Accuracy: 94.1%\n",
            "Batch 2000    Loss: 0.148    Accuracy: 94.3%\n",
            "Batch 2500    Loss: 0.146    Accuracy: 94.5%\n",
            "Batch 3000    Loss: 0.142    Accuracy: 94.8%\n",
            "Batch 3500    Loss: 0.142    Accuracy: 94.6%\n",
            "Batch 4000    Loss: 0.147    Accuracy: 94.8%\n",
            "Batch 4500    Loss: 0.158    Accuracy: 93.9%\n",
            "Batch 5000    Loss: 0.159    Accuracy: 93.8%\n",
            "Batch 5500    Loss: 0.142    Accuracy: 95.0%\n",
            "Batch 6000    Loss: 0.166    Accuracy: 94.0%\n",
            "\n",
            "Validation Loss: 0.164     Validation Accuracy: 87.5%\n",
            "********************************************************\n",
            "\n",
            "Epoch: 9\n",
            "\n",
            "Batch 500    Loss: 0.128    Accuracy: 95.2%\n",
            "Batch 1000    Loss: 0.120    Accuracy: 95.6%\n",
            "Batch 1500    Loss: 0.126    Accuracy: 95.3%\n",
            "Batch 2000    Loss: 0.137    Accuracy: 95.1%\n",
            "Batch 2500    Loss: 0.128    Accuracy: 95.5%\n",
            "Batch 3000    Loss: 0.132    Accuracy: 95.0%\n",
            "Batch 3500    Loss: 0.138    Accuracy: 94.8%\n",
            "Batch 4000    Loss: 0.139    Accuracy: 94.8%\n",
            "Batch 4500    Loss: 0.122    Accuracy: 95.5%\n",
            "Batch 5000    Loss: 0.129    Accuracy: 94.9%\n",
            "Batch 5500    Loss: 0.124    Accuracy: 95.4%\n",
            "Batch 6000    Loss: 0.137    Accuracy: 94.9%\n",
            "\n",
            "Validation Loss: 0.164     Validation Accuracy: 87.5%\n",
            "********************************************************\n",
            "\n",
            "Epoch: 10\n",
            "\n",
            "Batch 500    Loss: 0.102    Accuracy: 96.2%\n",
            "Batch 1000    Loss: 0.103    Accuracy: 96.0%\n",
            "Batch 1500    Loss: 0.104    Accuracy: 96.0%\n",
            "Batch 2000    Loss: 0.116    Accuracy: 95.3%\n",
            "Batch 2500    Loss: 0.119    Accuracy: 95.7%\n",
            "Batch 3000    Loss: 0.100    Accuracy: 96.0%\n",
            "Batch 3500    Loss: 0.129    Accuracy: 95.2%\n",
            "Batch 4000    Loss: 0.106    Accuracy: 96.1%\n",
            "Batch 4500    Loss: 0.111    Accuracy: 95.7%\n",
            "Batch 5000    Loss: 0.126    Accuracy: 95.0%\n",
            "Batch 5500    Loss: 0.118    Accuracy: 95.6%\n",
            "Batch 6000    Loss: 0.121    Accuracy: 95.6%\n",
            "\n",
            "Validation Loss: 0.075     Validation Accuracy: 100.0%\n",
            "********************************************************\n",
            "\n",
            "Training Complete\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch_index in range(num_epochs):\n",
        "  print(f'Epoch: {epoch_index + 1}\\n')\n",
        "\n",
        "  train_one_epoch()\n",
        "  validate_one_epoch()\n",
        "\n",
        "print('Training Complete')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}